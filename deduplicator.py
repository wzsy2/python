# deduplicator.py
import redis
import hashlib
from config import REDIS_CONFIG


class Deduplicator:
    """ç”µå½±å»é‡å™¨ï¼ŒåŸºäºRediså®ç°å»é‡åŠŸèƒ½"""

    def __init__(self, task_id):
        self.redis_client = redis.Redis(**REDIS_CONFIG)
        self.task_id = task_id
        self.key_prefix = f"movie_tracker:{task_id}"

    def _get_movie_hash(self, movie):
        """ç”Ÿæˆç”µå½±ä¿¡æ¯çš„å“ˆå¸Œå€¼ç”¨äºå»é‡"""
        content = movie['title'].strip().lower()  # åªä½¿ç”¨ç”µå½±æ ‡é¢˜
        return hashlib.md5(content.encode('utf-8')).hexdigest()

    def is_duplicate(self, movie):
        """æ£€æŸ¥ç”µå½±æ˜¯å¦é‡å¤"""
        movie_hash = self._get_movie_hash(movie)
        key = f"{self.key_prefix}:hashes"

        if self.redis_client.sismember(key, movie_hash):
            return True

        self.redis_client.sadd(key, movie_hash)
        return False

    def deduplicate(self, movies):
        """å¯¹ç”µå½±åˆ—è¡¨è¿›è¡Œå»é‡"""
        unique_movies = []
        duplicate_count = 0

        for movie in movies:
            if not self.is_duplicate(movie):
                unique_movies.append(movie)
            else:
                duplicate_count += 1

        if duplicate_count > 0:
            print(f"ğŸ” å»é‡å¤„ç†: å‘ç° {duplicate_count} éƒ¨é‡å¤ç”µå½±")

        return unique_movies

    def cleanup(self):
        """æ¸…ç†æœ¬æ¬¡ä»»åŠ¡çš„Redisæ•°æ®"""
        pattern = f"{self.key_prefix}:*"
        keys = self.redis_client.keys(pattern)

        if keys:
            self.redis_client.delete(*keys)
            print(f"ğŸ§¹ æ¸…ç†Redisæ•°æ®: {len(keys)} ä¸ªé”®")